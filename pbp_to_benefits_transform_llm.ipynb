{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5eff5b",
   "metadata": {},
   "source": [
    "# PBP → Benefits Translator (LangChain + Azure OpenAI)\n",
    "\n",
    "This notebook uses **LangChain** with your **Azure OpenAI** deployment to infer and validate\n",
    "a column mapping from `parse_pbp_files.csv` (parsed PBP) into the target schema defined by `benefits_ifp2.csv`.\n",
    "\n",
    "**Highlights**\n",
    "- LLM-assisted mapping proposal (JSON) using your source/target headers and a few-shot prompt.\n",
    "- Validation & auto-repair of the LLM's mapping output.\n",
    "- Fallback to deterministic matching (synonyms + fuzzy) if LLM is unavailable.\n",
    "- Numeric/percent coercions for cost-sharing fields.\n",
    "- Outputs `benefits_translated_llm.csv` aligned to the target schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d7a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running locally: ensure these are installed in your environment\n",
    "# pip install langchain langchain-openai pandas python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c99d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Configuration: Azure OpenAI via environment variables ----\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Required environment variables (example names):\n",
    "#   AZURE_OPENAI_API_KEY       = \"...\"\n",
    "#   AZURE_OPENAI_ENDPOINT      = \"https://<your-resource>.openai.azure.com/\"\n",
    "#   AZURE_OPENAI_API_VERSION   = \"2024-02-15-preview\"\n",
    "#   AZURE_OPENAI_CHAT_DEPLOYMENT = \"gpt-4o-mini\"      # your chat deployment name\n",
    "#   AZURE_OPENAI_EMBED_DEPLOYMENT = \"text-embedding-3-large\"  # optional\n",
    "\n",
    "missing = [k for k in [\n",
    "    \"AZURE_OPENAI_API_KEY\",\n",
    "    \"AZURE_OPENAI_ENDPOINT\",\n",
    "    \"AZURE_OPENAI_API_VERSION\",\n",
    "    \"AZURE_OPENAI_CHAT_DEPLOYMENT\"\n",
    "] if not os.getenv(k)]\n",
    "\n",
    "if missing:\n",
    "    print(\"⚠️ Missing Azure OpenAI env vars:\", missing)\n",
    "    print(\"   You can copy /mnt/data/azure_openai_example.env to .env and set your values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6856727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports ----\n",
    "import re, json\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da6aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Paths ----\n",
    "BASE = Path(\"/mnt/data\")\n",
    "PARSED_PBP = BASE / \"parse_pbp_files.csv\"\n",
    "TARGET_BENCHMARK = BASE / \"benefits_ifp2.csv\"\n",
    "OUTPUT = BASE / \"benefits_translated_llm.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38855ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Utilities ----\n",
    "def normalize_name(s: str) -> str:\n",
    "    s = (s or \"\").strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"_\", s)\n",
    "    s = re.sub(r\"_+\", \"_\", s).strip(\"_\")\n",
    "    return s\n",
    "\n",
    "def money_to_number(x):\n",
    "    import pandas as pd\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    s = str(x).strip()\n",
    "    if s == \"\":\n",
    "        return None\n",
    "    s = s.replace(\",\", \"\")\n",
    "    if s.endswith(\"%\"):\n",
    "        try:\n",
    "            return float(s.rstrip(\"%\")) / 100.0\n",
    "        except Exception:\n",
    "            return s\n",
    "    if s.startswith(\"$\"):\n",
    "        s = s[1:]\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return x\n",
    "\n",
    "def pick_best(source_cols, target_col, candidates_cache):\n",
    "    from difflib import get_close_matches\n",
    "    if target_col in candidates_cache:\n",
    "        return candidates_cache[target_col]\n",
    "    matches = get_close_matches(target_col, source_cols, n=1, cutoff=0.72)\n",
    "    best = matches[0] if matches else None\n",
    "    candidates_cache[target_col] = best\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Deterministic rules (synonyms & numeric-like) ----\n",
    "SYNONYMS = {\n",
    "    \"plan_id\": [\"contract_plan_id\",\"plan_id\",\"contract_plan\",\"pbp_id\",\"contract_pbpid\"],\n",
    "    \"segment_id\": [\"segment_id\",\"seg_id\"],\n",
    "    \"org_marketing_name\": [\"organization_marketing_name\",\"org_marketing_name\",\"parent_organization\"],\n",
    "    \"plan_marketing_name\": [\"plan_marketing_name\",\"plan_name\",\"marketing_name\",\"plan_marketing\"],\n",
    "    \"plan_type\": [\"plan_type\",\"org_type\",\"product_type\"],\n",
    "    \"county\": [\"county\",\"service_county\",\"service_area_county\"],\n",
    "    \"state\": [\"state\",\"service_state\",\"state_code\"],\n",
    "    \"zip\": [\"zip\",\"zipcode\",\"postal_code\"],\n",
    "    \"effective_year\": [\"year\",\"benefit_year\",\"effective_year\"],\n",
    "    \"medical_deductible\": [\"medical_deductible\",\"deductible_medical\",\"in_network_deductible\"],\n",
    "    \"drug_deductible\": [\"drug_deductible\",\"pharmacy_deductible\",\"rx_deductible\"],\n",
    "    \"moop_in_network\": [\"moop\",\"in_network_moop\",\"max_oop_in_network\",\"oop_max\"],\n",
    "    \"pcp_copay\": [\"pcp_copay\",\"primary_care_copay\",\"primary_care_visit_copay\",\"pcp_visit_copay\"],\n",
    "    \"specialist_copay\": [\"specialist_copay\",\"specialist_visit_copay\",\"spec_copay\"],\n",
    "    \"er_copay\": [\"er_copay\",\"emergency_room_copay\",\"emergency_care_copay\"],\n",
    "    \"urgent_care_copay\": [\"urgent_care_copay\",\"urgent_care_visit_copay\"],\n",
    "    \"inpatient_facility_per_stay\": [\"inpatient_per_stay\",\"inpatient_facility_per_stay\",\"inpatient_hospital_copay_per_stay\"],\n",
    "    \"outpatient_surgery_copay\": [\"outpatient_surgery_copay\",\"ambulatory_surgery_copay\",\"outpatient_facility_copay\"],\n",
    "    \"tier1_generic\": [\"tier1_generic_copay\",\"generic_copay\",\"pref_generic_copay\"],\n",
    "    \"tier2_pref_brand\": [\"tier2_preferred_brand_copay\",\"preferred_brand_copay\",\"pref_brand_copay\"],\n",
    "    \"tier3_nonpref_brand\": [\"tier3_nonpreferred_brand_copay\",\"nonpreferred_brand_copay\",\"nonpref_brand_copay\"],\n",
    "    \"tier4_specialty\": [\"tier4_specialty_copay\",\"specialty_copay\"],\n",
    "    \"dental_coverage\": [\"dental_benefit\",\"dental\",\"comprehensive_dental\"],\n",
    "    \"vision_coverage\": [\"vision_benefit\",\"vision\"],\n",
    "    \"hearing_coverage\": [\"hearing_benefit\",\"hearing\"],\n",
    "}\n",
    "\n",
    "NUMERIC_LIKE = {\n",
    "    \"medical_deductible\",\"drug_deductible\",\"moop_in_network\",\n",
    "    \"pcp_copay\",\"specialist_copay\",\"er_copay\",\"urgent_care_copay\",\n",
    "    \"inpatient_facility_per_stay\",\"outpatient_surgery_copay\",\n",
    "    \"tier1_generic\",\"tier2_pref_brand\",\"tier3_nonpref_brand\",\"tier4_specialty\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29a690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- LLM mapping proposal ----\n",
    "def propose_mapping_with_llm(source_cols, target_cols, model=None):\n",
    "    \"\"\"\n",
    "    Ask the LLM to produce a JSON mapping: { \"target_col\": \"best_source_col_or_null\", ... }\n",
    "    Return dict or None on failure.\n",
    "    \"\"\"\n",
    "    if model is None:\n",
    "        return None  # signal to caller to use fallback\n",
    "\n",
    "    sys = SystemMessage(content=(\n",
    "        \"You are a data integration assistant for Medicare PBP → benefits mapping. \"\n",
    "        \"Given source and target headers, return ONLY a compact JSON mapping \"\n",
    "        \"from target to source. Use null if no clear match. Do not explain.\"\n",
    "    ))\n",
    "\n",
    "    human = HumanMessage(content=f\"\"\"\n",
    "Create a JSON mapping from target → source.\n",
    "Target columns: {target_cols}\n",
    "Source columns: {source_cols}\n",
    "\n",
    "Rules:\n",
    "- Prefer exact semantic matches (PBP/PUF conventions).\n",
    "- If multiple candidates exist, pick the most specific.\n",
    "- If no good match, set value to null.\n",
    "Return JSON only.\n",
    "\"\"\")\n",
    "\n",
    "    try:\n",
    "        resp = model.invoke([sys, human])\n",
    "        txt = resp.content.strip()\n",
    "        start = txt.find(\"{\")\n",
    "        end = txt.rfind(\"}\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            txt = txt[start:end+1]\n",
    "        mapping = json.loads(txt)\n",
    "        if not isinstance(mapping, dict):\n",
    "            raise ValueError(\"LLM output is not a dict\")\n",
    "        return mapping\n",
    "    except Exception as e:\n",
    "        print(\"LLM mapping error → falling back. Reason:\", e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Pipeline: load, map, transform ----\n",
    "parsed_pbp = pd.read_csv(PARSED_PBP)\n",
    "target_benchmark = pd.read_csv(TARGET_BENCHMARK)\n",
    "\n",
    "target_cols = list(target_benchmark.columns)\n",
    "target_norm = [normalize_name(c) for c in target_cols]\n",
    "\n",
    "source_cols = list(parsed_pbp.columns)\n",
    "source_norm = [normalize_name(c) for c in source_cols]\n",
    "norm_to_source = {normalize_name(c): c for c in source_cols}\n",
    "\n",
    "# Instantiate LLM if env is ready\n",
    "llm = None\n",
    "try:\n",
    "    if all(os.getenv(k) for k in [\"AZURE_OPENAI_API_KEY\",\"AZURE_OPENAI_ENDPOINT\",\"AZURE_OPENAI_API_VERSION\",\"AZURE_OPENAI_CHAT_DEPLOYMENT\"]):\n",
    "        llm = AzureChatOpenAI(\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\"),\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "            temperature=0\n",
    "        )\n",
    "except Exception as e:\n",
    "    print(\"Failed to initialize AzureChatOpenAI → using fallback only. Reason:\", e)\n",
    "\n",
    "# Ask LLM for a mapping using original headers\n",
    "llm_mapping = propose_mapping_with_llm(list(parsed_pbp.columns), list(target_benchmark.columns), model=llm)\n",
    "\n",
    "# Build resolved sources\n",
    "resolved_sources = {}\n",
    "\n",
    "def resolve_with_synonyms_or_fuzzy(tnorm):\n",
    "    if tnorm in norm_to_source:\n",
    "        return norm_to_source[tnorm]\n",
    "    if tnorm in SYNONYMS:\n",
    "        for candidate in SYNONYMS[tnorm]:\n",
    "            if candidate in norm_to_source:\n",
    "                return norm_to_source[candidate]\n",
    "    best_norm = pick_best(source_norm, tnorm, candidates_cache)\n",
    "    if best_norm and best_norm in norm_to_source:\n",
    "        return norm_to_source[best_norm]\n",
    "    return None\n",
    "\n",
    "candidates_cache = {}\n",
    "if llm_mapping:\n",
    "    for tcol in target_cols:\n",
    "        src = llm_mapping.get(tcol)\n",
    "        src_final = None\n",
    "        if src:\n",
    "            if src in parsed_pbp.columns:\n",
    "                src_final = src\n",
    "            else:\n",
    "                nsrc = normalize_name(src)\n",
    "                src_final = norm_to_source.get(nsrc)\n",
    "        if not src_final:\n",
    "            src_final = resolve_with_synonyms_or_fuzzy(normalize_name(tcol))\n",
    "        if src_final:\n",
    "            resolved_sources[normalize_name(tcol)] = src_final\n",
    "else:\n",
    "    for tcol in target_cols:\n",
    "        tnorm = normalize_name(tcol)\n",
    "        src_final = resolve_with_synonyms_or_fuzzy(tnorm)\n",
    "        if src_final:\n",
    "            resolved_sources[tnorm] = src_final\n",
    "\n",
    "out = pd.DataFrame(columns=target_cols)\n",
    "\n",
    "for tcol, tnorm in zip(target_cols, target_norm):\n",
    "    src = resolved_sources.get(tnorm)\n",
    "    if src is None:\n",
    "        out[tcol] = None\n",
    "        continue\n",
    "    series = parsed_pbp[src]\n",
    "    if tnorm in NUMERIC_LIKE:\n",
    "        out[tcol] = series.apply(money_to_number)\n",
    "    else:\n",
    "        out[tcol] = series\n",
    "\n",
    "if \"plan_type\" in target_norm:\n",
    "    tname = target_cols[target_norm.index(\"plan_type\")]\n",
    "    out[tname] = out[tname].astype(str).str.upper().str.replace(\"MEDICARE \", \"\", regex=False)\n",
    "\n",
    "out.to_csv(OUTPUT, index=False)\n",
    "print(f\"✅ Wrote: {OUTPUT}\")\n",
    "out.head(10)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
